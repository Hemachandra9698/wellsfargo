# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/data/data_catalog.html

# specifying common parameters for datasets
_csv: &csv
  type: pandas.CSVDataSet
  load_args:
    sep: ","
    na_values: [ "#NA", NA ]
  save_args:
    index: False
    date_format: "%Y-%m-%d %H:%M"
    decimal: .


sample_data1:
  <<: *csv
  filepath: data/input/data_source_1/sample_data.1.csv


sample_data2:
  <<: *csv
  filepath: data/input/data_source_1/sample_data.2.dat
  load_args:
    sep: "|"

sample_data3:
  <<: *csv
  filepath: data/input/data_source_2/sample_data.3.dat

material_reference:
  <<: *csv
  filepath: data/input/data_source_2/material_reference.csv


# output params for storing intermediate results
# Un comment below for getting files for every file
#processed_sample_data1:
#  <<: *csv
#  filepath: data/02_intermediate/processed_sample_data1.csv
#
#processed_sample_data2:
#  <<: *csv
#  filepath: data/02_intermediate/processed_sample_data2.csv
#processed_sample_data3:
#  <<: *csv
#  filepath: data/02_intermediate/processed_sample_data3.csv

data2_aggregation_results:
  <<: *csv
  filepath: data/output/data2_aggregation_results.csv
  save_args:
    index: True

consolidated_output1:
  <<: *csv
  filepath: data/output/consolidated_output.1.csv